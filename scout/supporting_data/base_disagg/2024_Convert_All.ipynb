{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a654fe74-db43-4f1c-8b70-801683f35baa",
   "metadata": {},
   "source": [
    "### OUTPUT COLUMN NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812a794-435f-4986-a617-478efbb751ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### ResStock 2024 ComStock 2024\n",
    "import pandas as pd\n",
    "e_st = 'out.electricity.'\n",
    "r_st = '.energy_consumption'\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'no': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\n",
    "    'emm_intersect': [\"TRE\",\"FRCC\",\"MISW\",\"MISC\",\"MISE\",\"MISS\",\"ISNE\",\"NYCW\",\"NYUP\",\"PJME\",\"PJMW\",\"PJMC\",\"PJMD\",\"SRCA\",\"SRSE\",\"SRCE\",\"SPPS\",\"SPPC\",\"SPPN\",\"SRSG\",\"CANO\",\"CASO\",\"NWPP\",\"RMRG\",\"BASN\"]\n",
    "})\n",
    "\n",
    "def get_scout_geo():\n",
    "    file = 'scout_geography.csv'\n",
    "    df = pd.read_csv(file, dtype=str)\n",
    "\n",
    "    df['fips_code'] = df['fips_code'].str.zfill(5)\n",
    "    df['gisjoin'] = df['fips_code'].apply(\n",
    "        lambda x: 'G' + str(x)[:2] + '0' + str(x)[2:] + '0')\n",
    "    df.to_csv(f'new_{file}', index=False)\n",
    "    return df\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "indir = 'input'\n",
    "outdir = 'output'\n",
    "building_types = ['commercial','residential']\n",
    "substrings = [\".savings\", \"out.electricity.peak_\", \"out.electricity.total.\"]\n",
    "\n",
    "weathers = ['amy2018']\n",
    "for weath in weathers:\n",
    "    df_comstock = pd.read_parquet(f'./{indir}/2024_comstock/{weath}/baseline_metadata_and_annual_results.parquet', engine='pyarrow')\n",
    "    df_resstock = pd.read_parquet(f'./{indir}/2024_resstock/{weath}/baseline_metadata_and_annual_results.parquet', engine='pyarrow')\n",
    "\n",
    "\n",
    "output_file = \"DICT_ComStock2024.txt\"\n",
    "\n",
    "# Open the file in write mode and save the output\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(f'{weath} comstock\\n')\n",
    "    for col in df_comstock.columns:\n",
    "        # if (\"out.electricity.\" in col) and (all(sub not in col for sub in substrings)):\n",
    "        if (all(sub not in col for sub in substrings)):\n",
    "            f.write(f'{col}\\n')\n",
    "\n",
    "output_file = \"DICT_ResStock2024.txt\"\n",
    "\n",
    "# Open the file in write mode and save the output\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(f'{weath} resstock\\n')\n",
    "    for col in df_resstock.columns:\n",
    "        # if (\"out.electricity.\" in col) and (all(sub not in col for sub in substrings)):\n",
    "        if (all(sub not in col for sub in substrings)):\n",
    "            f.write(f'{col}\\n')\n",
    "\n",
    "\n",
    "# print(f'{weath} comstock')\n",
    "# for col in df_comstock.columns:\n",
    "#     # if (\"out.electricity.\" in col) and (all(sub not in col for sub in substrings)):\n",
    "#     if (all(sub not in col for sub in substrings)):\n",
    "#         print(col)\n",
    "        \n",
    "# print(f'{weath} resstock')\n",
    "# for col in df_resstock.columns:\n",
    "#     if (\"out.electricity.\" in col) and (all(sub not in col for sub in substrings)):\n",
    "#         print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dc19d-c5b7-4585-8a87-f15f46811656",
   "metadata": {},
   "source": [
    "### COMBINE HVAC TECH AND OTHER END USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91906768-b8d4-49c0-8b87-49943fbb8a08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "tech_dir = \"./output/2024_technology/\"\n",
    "end_use_dir = \"./output/2024_end_use/\"\n",
    "filenames = [\n",
    "    \"Com_Cdiv_EMM_amy2018\",\n",
    "    \"Com_Cdiv_State_amy2018\",\n",
    "    \"Res_Cdiv_EMM_amy2018\",\n",
    "    \"Res_Cdiv_State_amy2018\",\n",
    "    \"Com_Cdiv_EMM_amy2018_Stock\",\n",
    "    \"Com_Cdiv_State_amy2018_Stock\",\n",
    "    \"Res_Cdiv_EMM_amy2018_Stock\",\n",
    "    \"Res_Cdiv_State_amy2018_Stock\"\n",
    "    ]\n",
    "\n",
    "for filename in filenames:\n",
    "    # name, ext = os.path.splitext(filename)\n",
    "\n",
    "    if \"Stock\" in filename:\n",
    "        filename_eu = f\"{filename.replace('Stock','')}electricity_Stock.csv\"\n",
    "        filename_tech = f\"{filename.replace('Stock','')}electricity_Stock_Tech.csv\"\n",
    "    else:\n",
    "        filename_eu = f\"{filename}_electricity.csv\"\n",
    "        filename_tech = f\"{filename}_electricity_Tech.csv\"\n",
    "    \n",
    "    file_tech = os.path.join(tech_dir, filename_tech)\n",
    "    file_enduse = os.path.join(end_use_dir, filename_eu)\n",
    "    \n",
    "    df_tech = pd.read_csv(file_tech)\n",
    "    df_end_use = pd.read_csv(file_enduse)\n",
    "\n",
    "    print(f\"{filename_tech} {file_enduse}\")\n",
    "    \n",
    "    # Filter out rows where \"End use\" is \"Heating\" or \"Cooling\" in df_all\n",
    "    # df_end_use_filtered = df_end_use[~df_end_use['End use'].isin(['heating', 'cooling'])]\n",
    "    df_end_use_filtered = df_end_use\n",
    "    # Add the required columns to df_all_filtered with fixed values\n",
    "    df_end_use_filtered['Technology'] = \"all\"\n",
    "    \n",
    "    # Append df_all_filtered to df_tech\n",
    "    df_combined = pd.concat([df_tech, df_end_use_filtered], ignore_index=True)\n",
    "    \n",
    "    # Save the combined dataframe to a new CSV file (optional)\n",
    "    output_file = f\"./output/{filename_tech}\"\n",
    "    df_combined.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca19db-df62-416b-9d3f-56b2a02dfffa",
   "metadata": {},
   "source": [
    "### FILL NA with 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd4f88-cee0-44f4-8bb5-dda4b60cf325",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_paths = [\"./output/2024_end_use\",\"./output/2024_technology\"] \n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "    \n",
    "            if df.isnull().values.any():\n",
    "                df_filled = df.fillna(0)\n",
    "                output_filename = filename.replace(\".csv\", \".csv\")\n",
    "                output_path = os.path.join(folder_path, output_filename)\n",
    "                df_filled.to_csv(output_path, index=False)\n",
    "                print(f\"{filename}: Blank cells filled. Saved as {output_filename}\")\n",
    "            else:\n",
    "                print(f\"{filename}: No blank cell\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492307db-aed4-43a5-9831-3648abfd2d6f",
   "metadata": {},
   "source": [
    "### DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816919a1-525c-48b4-8cd8-4ccb6e0feef0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "enduse_map = {\n",
    "    \"commercial\": {\n",
    "        \"electricity\": {\n",
    "            \"heating\": [\n",
    "                \"out.electricity.heating.energy_consumption\",\n",
    "                \"out.electricity.heat_recovery.energy_consumption\"],\n",
    "            \"cooling\": [\n",
    "                \"out.electricity.heat_rejection.energy_consumption\",\n",
    "                \"out.electricity.cooling.energy_consumption\",\n",
    "                \"out.district_cooling.cooling.energy_consumption\"],\n",
    "            \"water heating\": [\"out.electricity.water_systems.energy_consumption\"],\n",
    "            \"fans and pumps\": [\n",
    "                \"out.electricity.fans.energy_consumption\",\n",
    "                \"out.electricity.pumps.energy_consumption\"],\n",
    "            \"lighting\": [\n",
    "                \"out.electricity.interior_lighting.energy_consumption\",\n",
    "                \"out.electricity.exterior_lighting.energy_consumption\"],\n",
    "            \"refrigeration\": [\"out.electricity.refrigeration.energy_consumption\"],\n",
    "            \"misc\": [\"out.electricity.interior_equipment.energy_consumption\"]\n",
    "        },\n",
    "        \"natural gas\":{\n",
    "            \"heating\": [\"out.natural_gas.heating.energy_consumption\",\n",
    "                        \"out.district_heating.heating.energy_consumption\"],\n",
    "            \"cooling\": [\"out.natural_gas.heating.energy_consumption\"],\n",
    "            \"water heating\": [\"out.natural_gas.water_systems.energy_consumption\",\n",
    "                              \"out.district_heating.water_systems.energy_consumption\"],\n",
    "            \"misc\": [\"out.natural_gas.interior_equipment.energy_consumption\"]\n",
    "        },\n",
    "        \"distillate\": {\n",
    "            \"heating\": [\"out.other_fuel.heating.energy_consumption\"],\n",
    "            \"cooling\": [\"out.other_fuel.cooling.energy_consumption\"],\n",
    "            \"water heating\": [\"out.other_fuel.water_systems.energy_consumption\"],\n",
    "            \"misc\": [\"out.natural_gas.interior_equipment.energy_consumption\"] \n",
    "        },\n",
    "        \"other fuel\": {\n",
    "            \"misc\": [\"out.natural_gas.interior_equipment.energy_consumption\"] \n",
    "        }\n",
    "    },\n",
    "    \"residential\": {\n",
    "        \"electricity\": {\n",
    "            \"heating\": [\n",
    "                \"out.electricity.heating.energy_consumption.kwh\",\n",
    "                \"out.electricity.heating_hp_bkup.energy_consumption.kwh\"],\n",
    "            \"cooling\": [\"out.electricity.cooling.energy_consumption.kwh\"],\n",
    "            \"water heating\": [\"out.electricity.hot_water.energy_consumption.kwh\"],\n",
    "            \"cooking\": [\"out.electricity.range_oven.energy_consumption.kwh\"],\n",
    "            \"drying\": [\"out.electricity.clothes_dryer.energy_consumption.kwh\"],\n",
    "            \"clothes washing\": [\"out.electricity.clothes_washer.energy_consumption.kwh\"],\n",
    "            \"dishwasher\": [\"out.electricity.dishwasher.energy_consumption.kwh\"],\n",
    "            \"lighting\": [\n",
    "                \"out.electricity.lighting_exterior.energy_consumption.kwh\",\n",
    "                \"out.electricity.lighting_interior.energy_consumption.kwh\",\n",
    "                \"out.electricity.lighting_garage.energy_consumption.kwh\"],\n",
    "            \"refrigeration\": [\n",
    "                \"out.electricity.freezer.energy_consumption.kwh\",\n",
    "                \"out.electricity.refrigerator.energy_consumption.kwh\"],\n",
    "            \"ceiling fan\": [\"out.electricity.ceiling_fan.energy_consumption.kwh\"],\n",
    "            \"misc\": [\"out.electricity.plug_loads.energy_consumption.kwh\"],\n",
    "            \"pool heaters\": [\"out.electricity.pool_heater.energy_consumption.kwh\"],\n",
    "            \"pool pumps\": [\"out.electricity.pool_pump.energy_consumption.kwh\"],\n",
    "            \"portable electric spas\": [\n",
    "                \"out.electricity.permanent_spa_heat.energy_consumption.kwh\",\n",
    "                \"out.electricity.permanent_spa_pump.energy_consumption.kwh\"],\n",
    "            \"fans and pumps\": [\n",
    "                \"out.electricity.mech_vent.energy_consumption.kwh\",\n",
    "                \"out.electricity.cooling_fans_pumps.energy_consumption.kwh\",\n",
    "                \"out.electricity.heating_fans_pumps.energy_consumption.kwh\",\n",
    "                \"out.electricity.heating_hp_bkup_fa.energy_consumption.kwh\",\n",
    "                \"out.electricity.well_pump.energy_consumption.kwh\"],\n",
    "        },\n",
    "        \"distillate\": {\n",
    "            \"heating\": [\n",
    "                \"out.fuel_oil.heating.energy_consumption.kwh\",\n",
    "                \"out.fuel_oil.heating_hp_bkup.energy_consumption.kwh\"],\n",
    "            \"water heating\": [\"out.fuel_oil.hot_water.energy_consumption.kwh\"],\n",
    "            \"misc\": [\"out.natural_gas.pool_heater.energy_consumption.kwh\"]\n",
    "        },\n",
    "        \"other fuel\": {\n",
    "            \"heating\": [\n",
    "                \"out.propane.heating.energy_consumption.kwh\",\n",
    "                \"out.propane.heating_hp_bkup.energy_consumption.kwh\"],\n",
    "            \"water heating\": [\"out.propane.hot_water.energy_consumption.kwh\"],\n",
    "            \"cooking\": [\"out.propane.range_oven.energy_consumption.kwh\"],\n",
    "            \"misc\": [\"out.natural_gas.pool_heater.energy_consumption.kwh\"],\n",
    "            \"drying\": [\"out.propane.clothes_dryer.energy_consumption.kwh\"]\n",
    "        },\n",
    "        \"natural gas\": {\n",
    "            \"heating\": [\n",
    "                \"out.natural_gas.heating.energy_consumption.kwh\",\n",
    "                \"out.natural_gas.heating_hp_bkup.energy_consumption.kwh\"],\n",
    "            \"cooling\": [\n",
    "                \"out.natural_gas.heating.energy_consumption.kwh\",\n",
    "                \"out.natural_gas.heating_hp_bkup.energy_consumption.kwh\"],\n",
    "            \"water heating\": [\"out.natural_gas.hot_water.energy_consumption.kwh\"],\n",
    "            \"cooking\": [\n",
    "                \"out.natural_gas.grill.energy_consumption.kwh\",\n",
    "                \"out.natural_gas.range_oven.energy_consumption.kwh\"],\n",
    "            \"drying\": [\"out.natural_gas.clothes_dryer.energy_consumption.kwh\"],\n",
    "            \"misc\": [\"out.natural_gas.pool_heater.energy_consumption.kwh\"]\n",
    "            # \"pool heaters\": [\"out.natural_gas.pool_heater.energy_consumption.kwh\"],\n",
    "            # \"portable electric spas\": [\"out.natural_gas.permanent_spa_heat.energy_consumption.kwh\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'no': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\n",
    "    'emm_intersect': [\"TRE\",\"FRCC\",\"MISW\",\"MISC\",\"MISE\",\"MISS\",\"ISNE\",\"NYCW\",\"NYUP\",\"PJME\",\"PJMW\",\"PJMC\",\"PJMD\",\"SRCA\",\"SRSE\",\"SRCE\",\"SPPS\",\"SPPC\",\"SPPN\",\"SRSG\",\"CANO\",\"CASO\",\"NWPP\",\"RMRG\",\"BASN\"]\n",
    "})\n",
    "\n",
    "stock_map = {\n",
    "    \"commercial\": {\n",
    "        \"stock\": [\"out.params.smallest_space_floor_area..m2\"]\n",
    "    },\n",
    "    \"residential\": {\n",
    "        \"stock\": [\"in.units_represented\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f3bfd-fa47-4f33-b24c-77227364b4e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fuel_enduse_map = {\n",
    "    \"commercial\": {\n",
    "        \"electricity\": {\n",
    "            \"cooling\": [\n",
    "                \"out.electricity.cooling.energy_consumption\",\n",
    "                \"out.electricity.heat_rejection.energy_consumption\"],\n",
    "            \"heating\": [\n",
    "                \"out.electricity.heating.energy_consumption\",\n",
    "                \"out.electricity.heat_recovery.energy_consumption\"],\n",
    "            # \"fans and pumps\": [\n",
    "            #     \"out.electricity.fans.energy_consumption\",\n",
    "            #     \"out.electricity.pumps.energy_consumption\"],\n",
    "            # \"water heating\": [\"out.electricity.water_systems.energy_consumption\"],\n",
    "            # \"lighting\": [\n",
    "            #     \"out.electricity.interior_lighting.energy_consumption\",\n",
    "            #     \"out.electricity.exterior_lighting.energy_consumption\"],\n",
    "            # \"refrigeration\": [\"out.electricity.refrigeration.energy_consumption\"],\n",
    "            # \"plug loads\": [\"out.electricity.interior_equipment.energy_consumption\"]\n",
    "        },\n",
    "        # \"other fuel\": {\n",
    "        #     \"cooling\": [\n",
    "        #         \"out.other_fuel.cooling.energy_consumption\"\n",
    "        #     ],\n",
    "        #     \"heating\": [\n",
    "        #         \"out.other_fuel.heating.energy_consumption\"\n",
    "        #     ],\n",
    "        #     \"water heating\": [\n",
    "        #         \"out.other_fuel.water_systems.energy_consumption\"\n",
    "        #     ]\n",
    "        # },\n",
    "        # \"natural_gas\": {\n",
    "        #     \"plug loads\": [\n",
    "        #         \"out.natural_gas.interior_equipment.energy_consumption\"\n",
    "        #     ],\n",
    "        #     \"heating\": [\n",
    "        #         \"out.natural_gas.heating.energy_consumption\"\n",
    "        #     ],\n",
    "        #     \"water heating\": [\n",
    "        #         \"out.natural_gas.water_systems.energy_consumption\"\n",
    "        #     ]\n",
    "        # }\n",
    "    },\n",
    "    \"residential\": {\n",
    "        \"electricity\": {\n",
    "            \"cooling\": [\"out.electricity.cooling.energy_consumption.kwh\"],\n",
    "            \"heating\": [\n",
    "                \"out.electricity.heating.energy_consumption.kwh\",\n",
    "                \"out.electricity.heating_hp_bkup.energy_consumption.kwh\"],\n",
    "            # \"water heating\": [\"out.electricity.hot_water.energy_consumption.kwh\"],\n",
    "            # \"cooking\": [\"out.electricity.range_oven.energy_consumption.kwh\"],\n",
    "            # \"drying\": [\"out.electricity.clothes_dryer.energy_consumption.kwh\"],\n",
    "            # \"clothes washing\": [\"out.electricity.clothes_washer.energy_consumption.kwh\"],\n",
    "            # \"dishwasher\": [\"out.electricity.dishwasher.energy_consumption.kwh\"],\n",
    "            # \"lighting\": [\n",
    "            #     \"out.electricity.lighting_exterior.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.lighting_interior.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.lighting_garage.energy_consumption.kwh\"],\n",
    "            # \"refrigeration\": [\n",
    "            #     \"out.electricity.freezer.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.refrigerator.energy_consumption.kwh\"],\n",
    "            # \"ceiling fan\": [\"out.electricity.ceiling_fan.energy_consumption.kwh\"],\n",
    "            # \"fans and pumps\": [\n",
    "            #     \"out.electricity.mech_vent.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.cooling_fans_pumps.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.heating_fans_pumps.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.heating_hp_bkup_fa.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.well_pump.energy_consumption.kwh\"],\n",
    "            # \"plug loads\": [\"out.electricity.plug_loads.energy_consumption.kwh\"],\n",
    "            # \"pool heaters\": [\"out.electricity.pool_heater.energy_consumption.kwh\"],\n",
    "            # \"pool pumps\": [\"out.electricity.pool_pump.energy_consumption.kwh\"],\n",
    "            # \"portable electric spas\": [\n",
    "            #     \"out.electricity.permanent_spa_heat.energy_consumption.kwh\",\n",
    "            #     \"out.electricity.permanent_spa_pump.energy_consumption.kwh\"]\n",
    "        },\n",
    "        # \"oil\": {\n",
    "        #     \"heating\": [\n",
    "        #         \"out.fuel_oil.heating.energy_consumption.kwh\",\n",
    "        #         \"out.fuel_oil.heating_hp_bkup.energy_consumption.kwh\",\n",
    "        #     ],\n",
    "        #     \"water heating\": [\n",
    "        #         \"out.fuel_oil.hot_water.energy_consumption.kwh\"\n",
    "        #     ]\n",
    "        # },\n",
    "        # \"natural_gas\": {\n",
    "        #     \"drying\": [\n",
    "        #         \"out.natural_gas.clothes_dryer.energy_consumption.kwh\"\n",
    "        #     ],\n",
    "        #     \"cooking\": [\n",
    "        #         \"out.natural_gas.grill.energy_consumption.kwh\",\n",
    "        #         \"out.natural_gas.range_oven.energy_consumption.kwh\",\n",
    "        #         \"out.natural_gas.range_oven.energy_consumption.kwh\"\n",
    "        #     ],\n",
    "        #     \"heating\": [\n",
    "        #         \"out.natural_gas.heating.energy_consumption.kwh\",\n",
    "        #         \"out.natural_gas.heating_hp_bkup.energy_consumption.kwh\"\n",
    "        #     ],\n",
    "        #     \"water heating\": [\n",
    "        #         \"out.natural_gas.hot_water.energy_consumption.kwh\"\n",
    "        #     ],\n",
    "        #     \"lighting\": [\n",
    "        #         \"out.natural_gas.lighting.energy_consumption.kwh\",\n",
    "        #     ],\n",
    "        #     \"pool heaters\": [\n",
    "        #         \"out.natural_gas.pool_heater.energy_consumption.kwh\"\n",
    "        #     ],\n",
    "        #     \"portable electric spas\": [\n",
    "        #         \"out.natural_gas.permanent_spa_heat.energy_consumption.kwh\"\n",
    "        #     ]\n",
    "        # },\n",
    "        # \"propane\": {\n",
    "        #     \"heating\": [\n",
    "        #         \"out.propane.heating.energy_consumption.kwh\",\n",
    "        #         \"out.propane.heating_hp_bkup.energy_consumption.kwh\",\n",
    "        #     ],\n",
    "        #     \"water heating\" : [\n",
    "        #         \"out.propane.hot_water.energy_consumption.kwh\"\n",
    "        #     ],\n",
    "        #     \"drying\": [\n",
    "        #         \"out.propane.clothes_dryer.energy_consumption.kwh\"\n",
    "        #     ],\n",
    "        #     \"cooking\": [\n",
    "        #         \"out.propane.range_oven.energy_consumption.kwh\"\n",
    "        #     ]\n",
    "        # }\n",
    "    }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021254c-38b9-453f-b2ed-25ce2f357baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def remove_space(string):\n",
    "    return string.replace(\" \", \"\")\n",
    "\n",
    "def get_scout_geo():\n",
    "    file = 'scout_geography.csv'\n",
    "    df = pd.read_csv(file, dtype=str)\n",
    "    \n",
    "    df['fips_code'] = df['fips_code'].str.zfill(5)\n",
    "    df['gisjoin'] = df['fips_code'].apply(\n",
    "        lambda x: 'G' + str(x)[:2] + '0' + str(x)[2:] + '0')\n",
    "    # df.loc[df['state'] == 'AK', 'gisjoin'] = 'G0'\n",
    "    # df.loc[df['state'] == 'HI', 'gisjoin'] = 'G1'\n",
    "    \n",
    "    df.loc[df['state'] == 'AK', 'emm2020_county'] = 'AK_HI'\n",
    "    df.loc[df['state'] == 'HI', 'emm2020_county'] = 'AK_HI'\n",
    "    df.to_csv(f'new_{file}', index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def transpose(df):\n",
    "    return df.transpose()\n",
    "\n",
    "def combine_keys(_dict):\n",
    "    combined_dict = {}\n",
    "\n",
    "    for fuel_type, categories in _dict.items():\n",
    "        for category, values in categories.items():\n",
    "            combined_key = f\"{fuel_type}_{category.replace(' ', '_')}\"\n",
    "            combined_dict[combined_key] = values\n",
    "    \n",
    "    return combined_dict\n",
    "def contains_utf8(text):\n",
    "    try:\n",
    "        text.encode('ascii')  # Try encoding to ASCII (UTF-8 characters will fail)\n",
    "        return False\n",
    "    except UnicodeEncodeError:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54656dc0-1857-4740-b5e1-b5cb49a4c264",
   "metadata": {},
   "source": [
    "### CDIV/EMM - ENERGY (TECH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a6014-6fa4-4308-a643-5508bb17702a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    df.loc[df['state'] == 'HI', 'county'] = 'G1'        \n",
    "    for geo in geos:\n",
    "        geocol = 'emm2020_county' if geo == 'emm' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)\n",
    "    df = df.drop('county', axis=1)\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    merged_matrix = df.merge(df_order, left_on='emm', right_on='emm_intersect', how='left')\n",
    "    sorted_matrix = merged_matrix.sort_values(by='no')\n",
    "    sorted_matrix = sorted_matrix.drop(sorted_matrix.columns[-2:], axis=1)\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "\n",
    "    return(sorted_matrix)\n",
    "\n",
    "\n",
    "def replace_col_vals(df, tech):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=['Technology'], inplace=True)\n",
    "    df.insert(0, 'Technology', tech)\n",
    "    return df\n",
    "    \n",
    "def convert_matrix(sector,filedir, filename, weathers, mymap):\n",
    "\n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        sec = \"Res\"\n",
    "        \n",
    "    combined_map = combine_keys(mymap[sector])\n",
    "    mykeys = list(combined_map)\n",
    "    \n",
    "    for weath in weathers:\n",
    "        # weath = 'tmy3'\n",
    "        df_all = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        df_all.rename(columns={county_col: 'county'}, inplace=True)\n",
    "        df_all.rename(columns={'in.state': 'state'}, inplace=True)\n",
    "        \n",
    "        df_all.reset_index(inplace=True)\n",
    "        df_all = apply_geographies(df_all, scoutgeo_df, geos)\n",
    "        df_all = df_all.dropna(subset=geos)\n",
    "\n",
    "        all_eu = pd.DataFrame()\n",
    "        for eu in mykeys:\n",
    "            df = df_all.copy()\n",
    "            df[eu] = df[combined_map[eu]].sum(axis=1)\n",
    "            df = df[df[eu]>0]\n",
    "            mapfile = f\"map_{sector[:3]}_{eu}.csv\"\n",
    "            map_df = pd.read_csv(f\"./{fdir}/mapping/{mapfile}\")\n",
    "\n",
    "            df['scout_tech'] = None\n",
    "            for _, map_row in map_df.iterrows():\n",
    "                condition = pd.Series(True, index=df.index)\n",
    "                for col in map_df.columns:\n",
    "                    if col != 'scout_tech' and col in df.columns:\n",
    "                        condition &= (df[col] == map_row[col])\n",
    "                df.loc[condition, 'scout_tech'] = map_row['scout_tech']\n",
    "            matched_rows = df[df['scout_tech'].notna()]\n",
    "            columns_to_keep = geos + ['scout_tech'] + [eu]\n",
    "            df = df[columns_to_keep]\n",
    "            tech_list = df['scout_tech'].unique().tolist()\n",
    "            # ######## DEBUG ##################\n",
    "            # print(f\"END USE {eu}\")\n",
    "            # print(df.shape[0])\n",
    "            # with pd.option_context('display.max_columns', None):\n",
    "            #     for col in df.columns:\n",
    "            #         print(col)\n",
    "            # ######## DEBUG ##################\n",
    "            \n",
    "            df = df.groupby(['emm', 'cdiv', 'scout_tech']).sum().reset_index()\n",
    "\n",
    "            all_tech = pd.DataFrame()\n",
    "            for tech in tech_list:\n",
    "\n",
    "                convert_pd = pd.DataFrame()\n",
    "                tdf = df[(df['scout_tech'] == tech)]\n",
    "                tdf = tdf.drop(columns=['scout_tech'])\n",
    "                conversion_matrix = tdf.pivot(index='emm', columns='cdiv', values=eu)\n",
    "                convert_matrix = output(conversion_matrix.reset_index())\n",
    "                convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "                normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "                normalized_matrix = output(normalized_matrix)\n",
    "                normalized_matrix = normalized_matrix.fillna(0)\n",
    "                normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "                normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "                normalized_matrix = normalized_matrix.iloc[1:]\n",
    "                normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "                normalized_matrix.insert(0, 'End use',  eu.split('_')[1])\n",
    "                normalized_matrix.insert(0, 'Technology', tech)\n",
    "                if (normalized_matrix['Total'] != 0).all():\n",
    "                    normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "                    all_tech = normalized_matrix if all_tech.empty else pd.concat([all_tech, normalized_matrix], ignore_index=False)\n",
    "                    if tech == \"res_type_central_AC\":\n",
    "                        norm2 = replace_col_vals(normalized_matrix, \"wall-window_room_AC\")\n",
    "                        all_tech = pd.concat([all_tech, norm2], ignore_index=False)\n",
    "            all_eu = all_tech if all_eu.empty else pd.concat([all_eu, all_tech], ignore_index=False)\n",
    "        all_eu.to_csv(f\"./{outdir}/{sec}_Cdiv_EMM_{weath}__electricity_Tech.csv\", index=False)\n",
    "\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_technology'\n",
    "geos = ['emm', 'cdiv']\n",
    "\n",
    "print(\"COMMERCIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"commercial\",\n",
    "    filedir = f\"./{fdir}/2024_comstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "print(\"RESIDENTIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"residential\",\n",
    "    filedir = f\"./{fdir}/2024_resstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "\n",
    "print(\"COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d0026-8878-4c7e-b27c-82e6603ed9cf",
   "metadata": {},
   "source": [
    "### CDIV/EMM - STOCK (TECH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084cd042-958e-4b5f-8961-f9e7a80b4f6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    df.loc[df['state'] == 'HI', 'county'] = 'G1'        \n",
    "    for geo in geos:\n",
    "        geocol = 'emm2020_county' if geo == 'emm' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)\n",
    "    df = df.drop('county', axis=1)\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    merged_matrix = df.merge(df_order, left_on='emm', right_on='emm_intersect', how='left')\n",
    "    sorted_matrix = merged_matrix.sort_values(by='no')\n",
    "    sorted_matrix = sorted_matrix.drop(sorted_matrix.columns[-2:], axis=1)\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "\n",
    "    return(sorted_matrix)\n",
    "\n",
    "\n",
    "def replace_col_vals(df, tech):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=['Technology'], inplace=True)\n",
    "    df.insert(0, 'Technology', tech)\n",
    "    return df\n",
    "    \n",
    "def convert_matrix(sector,filedir, filename, weathers, mymap):\n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        # area_col = \"weight\"\n",
    "        area_col = \"calc.weighted.sqft\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        area_col = \"in.units_represented\"\n",
    "        sec = \"Res\"\n",
    "        \n",
    "    combined_map = combine_keys(mymap[sector])\n",
    "    mykeys = list(combined_map)\n",
    "    \n",
    "    for weath in weathers:\n",
    "        # weath = 'tmy3'\n",
    "        df_all = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        df_all.rename(columns={county_col: 'county'}, inplace=True)\n",
    "        df_all.rename(columns={'in.state': 'state'}, inplace=True)\n",
    "        df_all.rename(columns={area_col: \"warea\"}, inplace=True)\n",
    "        \n",
    "        df_all.reset_index(inplace=True)\n",
    "        df_all = apply_geographies(df_all, scoutgeo_df, geos)\n",
    "        df_all = df_all.dropna(subset=geos)\n",
    "\n",
    "        all_eu = pd.DataFrame()\n",
    "        for eu in mykeys:\n",
    "            df = df_all.copy()\n",
    "            df[eu] = df[combined_map[eu]].sum(axis=1)\n",
    "            df = df[df[eu]>0]\n",
    "            mapfile = f\"map_{sector[:3]}_{eu}.csv\"\n",
    "            map_df = pd.read_csv(f\"./{fdir}/mapping/{mapfile}\")\n",
    "\n",
    "            df['scout_tech'] = None\n",
    "            for _, map_row in map_df.iterrows():\n",
    "                condition = pd.Series(True, index=df.index)\n",
    "                for col in map_df.columns:\n",
    "                    if col != 'scout_tech' and col in df.columns:\n",
    "                        condition &= (df[col] == map_row[col])\n",
    "                df.loc[condition, 'scout_tech'] = map_row['scout_tech']\n",
    "            matched_rows = df[df['scout_tech'].notna()]\n",
    "            columns_to_keep = geos + ['scout_tech'] + [eu, 'warea']\n",
    "            df = df[columns_to_keep]\n",
    "            tech_list = df['scout_tech'].unique().tolist()            \n",
    "            # df = df.groupby(['emm', 'cdiv', 'scout_tech']).sum().reset_index()\n",
    "            \n",
    "            all_tech = pd.DataFrame()\n",
    "            for tech in tech_list:\n",
    "\n",
    "                convert_pd = pd.DataFrame()\n",
    "                tdf = df[(df['scout_tech'] == tech)]\n",
    "                tdf = tdf.drop(columns=['scout_tech'])\n",
    "                \n",
    "                tdf_temp = tdf[['emm', 'cdiv', 'warea', eu]]\n",
    "                mask = (tdf_temp[[eu]] != 0).all(axis=1)\n",
    "                tedf = tdf_temp[mask]\n",
    "\n",
    "                conversion_matrix = tedf.pivot_table(index='emm', columns='cdiv', values=\"warea\", aggfunc='sum')\n",
    "                convert_matrix = output(conversion_matrix.reset_index())\n",
    "                convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "                normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "                normalized_matrix = output(normalized_matrix)\n",
    "                normalized_matrix = normalized_matrix.fillna(0)\n",
    "                normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "                normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "                normalized_matrix = normalized_matrix.iloc[1:]\n",
    "                normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "                normalized_matrix.insert(0, 'End use',  eu.split('_')[1])\n",
    "                normalized_matrix.insert(0, 'Technology', tech)\n",
    "                if (normalized_matrix['Total'] != 0).all():\n",
    "                    normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "                    all_tech = normalized_matrix if all_tech.empty else pd.concat([all_tech, normalized_matrix], ignore_index=False)\n",
    "                    if tech == \"res_type_central_AC\":\n",
    "                        norm2 = replace_col_vals(normalized_matrix, \"wall-window_room_AC\")\n",
    "                        all_tech = pd.concat([all_tech, norm2], ignore_index=False)\n",
    "            all_eu = all_tech if all_eu.empty else pd.concat([all_eu, all_tech], ignore_index=False)\n",
    "        all_eu.to_csv(f\"./{outdir}/{sec}_Cdiv_EMM_{weath}_electricity_Stock_Tech.csv\", index=False)\n",
    "\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_technology'\n",
    "geos = ['emm', 'cdiv']\n",
    "\n",
    "print(\"COMMERCIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"commercial\",\n",
    "    filedir = f\"./{fdir}/2024_comstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "print(\"RESIDENTIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"residential\",\n",
    "    filedir = f\"./{fdir}/2024_resstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "\n",
    "print(\"COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0763f-ff9e-4ca3-8d02-7ec9a04c7f03",
   "metadata": {},
   "source": [
    "### CDIV/STATE - ENERGY (TECH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e74341-e59a-4890-9f26-f3f7a3826b81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    df.loc[df['state'] == 'HI', 'county'] = 'G1'        \n",
    "    for geo in geos:\n",
    "        geocol = 'cdiv' if geo == 'cdiv' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)\n",
    "    df = df.drop('county', axis=1)\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    sorted_matrix = df\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "    return(sorted_matrix)\n",
    "    \n",
    "def replace_col_vals(df, tech):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=['Technology'], inplace=True)\n",
    "    df.insert(0, 'Technology', tech)\n",
    "    return df\n",
    "    \n",
    "def convert_matrix(sector,filedir, filename, weathers, mymap):\n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        sec = \"Res\"        \n",
    "    combined_map = combine_keys(mymap[sector])\n",
    "    mykeys = list(combined_map)\n",
    "    \n",
    "    for weath in weathers:\n",
    "        # weath = 'tmy3'\n",
    "        df_all = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        df_all.rename(columns={county_col: 'county'}, inplace=True)\n",
    "        df_all.rename(columns={'in.state': 'state'}, inplace=True)\n",
    "        \n",
    "        df_all.reset_index(inplace=True)\n",
    "        df_all = apply_geographies(df_all, scoutgeo_df, geos)\n",
    "        df_all = df_all.dropna(subset=geos)\n",
    "\n",
    "        all_eu = pd.DataFrame()\n",
    "        for eu in mykeys:\n",
    "            df = df_all.copy()\n",
    "            df[eu] = df[combined_map[eu]].sum(axis=1)\n",
    "            df = df[df[eu]>0]\n",
    "            mapfile = f\"map_{sector[:3]}_{eu}.csv\"\n",
    "            map_df = pd.read_csv(f\"./{fdir}/mapping/{mapfile}\")\n",
    "\n",
    "            df['scout_tech'] = None\n",
    "            for _, map_row in map_df.iterrows():\n",
    "                condition = pd.Series(True, index=df.index)\n",
    "                for col in map_df.columns:\n",
    "                    if col != 'scout_tech' and col in df.columns:\n",
    "                        condition &= (df[col] == map_row[col])\n",
    "                df.loc[condition, 'scout_tech'] = map_row['scout_tech']\n",
    "            matched_rows = df[df['scout_tech'].notna()]\n",
    "            columns_to_keep = geos + ['scout_tech'] + [eu]\n",
    "            df = df[columns_to_keep]\n",
    "            tech_list = df['scout_tech'].unique().tolist()            \n",
    "            df = df.groupby(['state', 'cdiv', 'scout_tech']).sum().reset_index()\n",
    "\n",
    "            all_tech = pd.DataFrame()\n",
    "            for tech in tech_list:\n",
    "\n",
    "                convert_pd = pd.DataFrame()\n",
    "                tdf = df[(df['scout_tech'] == tech)]\n",
    "                tdf = tdf.drop(columns=['scout_tech'])\n",
    "                conversion_matrix = tdf.pivot(index='state', columns='cdiv', values=eu)\n",
    "                convert_matrix = output(conversion_matrix.reset_index())\n",
    "                convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "                normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "                normalized_matrix = output(normalized_matrix)\n",
    "                normalized_matrix = normalized_matrix.fillna(0)\n",
    "                normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "                normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "                normalized_matrix = normalized_matrix.iloc[1:]\n",
    "                normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "                normalized_matrix.insert(0, 'End use',  eu.split('_')[1])\n",
    "                normalized_matrix.insert(0, 'Technology', tech)\n",
    "                if (normalized_matrix['Total'] != 0).all():\n",
    "                    normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "                    all_tech = normalized_matrix if all_tech.empty else pd.concat([all_tech, normalized_matrix], ignore_index=False)\n",
    "                    if tech == \"res_type_central_AC\":\n",
    "                        norm2 = replace_col_vals(normalized_matrix, \"wall-window_room_AC\")\n",
    "                        all_tech = pd.concat([all_tech, norm2], ignore_index=False)   \n",
    "            all_eu = all_tech if all_eu.empty else pd.concat([all_eu, all_tech], ignore_index=False)\n",
    "        all_eu.to_csv(f\"./{outdir}/{sec}_Cdiv_State_{weath}_electricity_Tech.csv\", index=False)\n",
    "\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_technology'\n",
    "geos = ['cdiv','state']\n",
    "\n",
    "print(\"COMMERCIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"commercial\",\n",
    "    filedir = f\"./{fdir}/2024_comstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "\n",
    "print(\"RESIDENTIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"residential\",\n",
    "    filedir = f\"./{fdir}/2024_resstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "\n",
    "print(\"COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1771820-e08b-4d03-a137-cb29630bc6f7",
   "metadata": {},
   "source": [
    "### CDIV/STATE - STOCK (TECH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbd969-e13c-4930-a890-6ea6258468d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    df.loc[df['state'] == 'HI', 'county'] = 'G1'        \n",
    "    for geo in geos:\n",
    "        geocol = 'cdiv' if geo == 'cdiv' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)          \n",
    "    df = df.drop('county', axis=1)\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    sorted_matrix = df\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "    return(sorted_matrix)\n",
    "\n",
    "\n",
    "def replace_col_vals(df, tech):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=['Technology'], inplace=True)\n",
    "    df.insert(0, 'Technology', tech)\n",
    "    return df\n",
    "    \n",
    "def convert_matrix(sector,filedir, filename, weathers, mymap):        \n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        # area_col = \"weight\"\n",
    "        area_col = \"calc.weighted.sqft\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        area_col = \"in.units_represented\"\n",
    "        sec = \"Res\"\n",
    "    \n",
    "    combined_map = combine_keys(mymap[sector])\n",
    "    mykeys = list(combined_map)\n",
    "    \n",
    "    for weath in weathers:\n",
    "        # weath = 'tmy3'\n",
    "        df_all = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        df_all.rename(columns={county_col: 'county'}, inplace=True)\n",
    "        df_all.rename(columns={'in.state': 'state'}, inplace=True)\n",
    "        df_all.rename(columns={area_col: \"warea\"}, inplace=True)\n",
    "        \n",
    "        df_all.reset_index(inplace=True)\n",
    "        df_all = apply_geographies(df_all, scoutgeo_df, geos)\n",
    "        df_all = df_all.dropna(subset=geos)\n",
    "\n",
    "        all_eu = pd.DataFrame()\n",
    "        for eu in mykeys:\n",
    "            df = df_all.copy()\n",
    "            # print(f\"END USE= {eu}\")\n",
    "            df[eu] = df[combined_map[eu]].sum(axis=1)\n",
    "            df = df[df[eu]>0]\n",
    "            mapfile = f\"map_{sector[:3]}_{eu}.csv\"\n",
    "            map_df = pd.read_csv(f\"./{fdir}/mapping/{mapfile}\")\n",
    "\n",
    "            df['scout_tech'] = None\n",
    "            for _, map_row in map_df.iterrows():\n",
    "                condition = pd.Series(True, index=df.index)\n",
    "                for col in map_df.columns:\n",
    "                    if col != 'scout_tech' and col in df.columns:\n",
    "                        condition &= (df[col] == map_row[col])\n",
    "                df.loc[condition, 'scout_tech'] = map_row['scout_tech']\n",
    "            matched_rows = df[df['scout_tech'].notna()]\n",
    "            columns_to_keep = geos + ['scout_tech'] + [eu,'warea']\n",
    "            df = df[columns_to_keep]\n",
    "            tech_list = df['scout_tech'].unique().tolist()\n",
    "            # df = df.groupby(['state', 'cdiv', 'scout_tech']).sum().reset_index()\n",
    "            all_tech = pd.DataFrame()\n",
    "            for tech in tech_list:\n",
    "\n",
    "                convert_pd = pd.DataFrame()\n",
    "                tdf = df[(df['scout_tech'] == tech)]\n",
    "                tdf = tdf.drop(columns=['scout_tech'])\n",
    "                \n",
    "                tdf_temp = tdf[['state', 'cdiv', 'warea', eu]]\n",
    "                mask = (tdf_temp[[eu]] != 0).all(axis=1)\n",
    "                tedf = tdf_temp[mask]\n",
    "\n",
    "                conversion_matrix = tedf.pivot_table(index='state', columns='cdiv', values=\"warea\", aggfunc='sum')\n",
    "                convert_matrix = output(conversion_matrix.reset_index())\n",
    "                convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "                normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "                normalized_matrix = output(normalized_matrix)\n",
    "                normalized_matrix = normalized_matrix.fillna(0)\n",
    "                normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "                normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "                normalized_matrix = normalized_matrix.iloc[1:]\n",
    "                normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "                normalized_matrix.insert(0, 'End use',  eu.split('_')[1])\n",
    "                normalized_matrix.insert(0, 'Technology', tech)\n",
    "                if (normalized_matrix['Total'] != 0).all():\n",
    "                    normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "                    all_tech = normalized_matrix if all_tech.empty else pd.concat([all_tech, normalized_matrix], ignore_index=False)\n",
    "                    if tech == \"res_type_central_AC\":\n",
    "                        norm2 = replace_col_vals(normalized_matrix, \"wall-window_room_AC\")\n",
    "                        all_tech = pd.concat([all_tech, norm2], ignore_index=False)\n",
    "            all_eu = all_tech if all_eu.empty else pd.concat([all_eu, all_tech], ignore_index=False)\n",
    "        all_eu.to_csv(f\"./{outdir}/{sec}_Cdiv_State_{weath}_electricity_Stock_Tech.csv\", index=False)\n",
    "\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_technology'\n",
    "geos = ['cdiv','state']\n",
    "\n",
    "print(\"COMMERCIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"commercial\",\n",
    "    filedir = f\"./{fdir}/2024_comstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "print(\"RESIDENTIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"residential\",\n",
    "    filedir = f\"./{fdir}/2024_resstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = fuel_enduse_map)\n",
    "\n",
    "print(\"COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7d432-5a77-4e13-9de5-7052de9a4277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69551561-27cf-4f2a-8c1a-76908de6165e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b76d7bca-1c1b-4db2-b0d1-30e72fc5d96f",
   "metadata": {},
   "source": [
    "### CDIV/EMM - ENERGY (END USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfcdd0-8b30-4683-9d50-894b1eff2cce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Energy ####\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    # df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    # df.loc[df['state'] == 'HI', 'county'] = 'G1'        \n",
    "    for geo in geos:\n",
    "        geocol = 'emm2020_county' if geo == 'emm' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)\n",
    "    df = df.drop('county', axis=1)\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    merged_matrix = df.merge(df_order, left_on='emm', right_on='emm_intersect', how='left')\n",
    "    sorted_matrix = merged_matrix.sort_values(by='no')\n",
    "    sorted_matrix = sorted_matrix.drop(sorted_matrix.columns[-2:], axis=1)\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "\n",
    "    return(sorted_matrix)\n",
    "\n",
    "\n",
    "def convert_matrix(sector,filedir, filename, weathers, mymap, fueltype):\n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        sec = \"Res\"\n",
    "    \n",
    "    mykeys = list(mymap[sector][fueltype])\n",
    "\n",
    "    for weath in weathers:\n",
    "        df = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        df.rename(columns={county_col: 'county'}, inplace=True)\n",
    "        df.rename(columns={'in.state': 'state'}, inplace=True)\n",
    "\n",
    "        for eu in mykeys:\n",
    "            df[eu] = df[mymap[sector][fueltype][eu]].sum(axis=1)\n",
    "        df.reset_index(inplace=True)\n",
    "        df = apply_geographies(df, scoutgeo_df, geos)\n",
    "        df = df.dropna(subset=geos)\n",
    "        df = df[geos+mykeys]\n",
    "        df = df.groupby(['emm','cdiv']).sum().reset_index()\n",
    "        norm_pd = pd.DataFrame()\n",
    "        convert_pd = pd.DataFrame()\n",
    "        for eu in mykeys:\n",
    "\n",
    "            conversion_matrix = df.pivot(index='emm', columns='cdiv', values=eu)\n",
    "            convert_matrix = output(conversion_matrix.reset_index())\n",
    "            convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "            normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "            normalized_matrix = output(normalized_matrix)\n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "            normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "            normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "            normalized_matrix = normalized_matrix.iloc[1:]\n",
    "            normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "            normalized_matrix.insert(0, 'End use', eu)\n",
    "            normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "            norm_pd = normalized_matrix if norm_pd.empty else pd.concat([norm_pd, normalized_matrix], ignore_index=False)\n",
    "        if sec == \"Res\": norm_pd['AK_HI'] = 0    \n",
    "        norm_pd.to_csv(f\"./{outdir}/{sec}_Cdiv_EMM_{weath}_{remove_space(fueltype)}.csv\", index=False)\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_end_use'\n",
    "building_types = ['commercial','residential']\n",
    "geos = ['emm', 'cdiv']\n",
    "fuel_com = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "fuel_res = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "################################################################################\n",
    "print(\"COMMERCIAL\")\n",
    "\n",
    "for fl in fuel_com:\n",
    "    convert_matrix(\n",
    "        sector = \"commercial\",\n",
    "        filedir = f\"./{fdir}/2024_comstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype = fl)\n",
    "\n",
    "print(\"RESIDENTIAL\")\n",
    "for fl in fuel_res:\n",
    "    convert_matrix(\n",
    "        sector = \"residential\",\n",
    "        filedir = f\"./{fdir}/2024_resstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],#,'tmy3'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype = fl)\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4465e27-742a-4eb3-8066-fcad62ea1252",
   "metadata": {},
   "source": [
    "### CDIV/EMM - STOCK (END USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afb22a-56e3-4323-b420-dd824bd7521f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    # df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    # df.loc[df['state'] == 'HI', 'county'] = 'G1'        \n",
    "    for geo in geos:\n",
    "        geocol = 'emm2020_county' if geo == 'emm' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)\n",
    "    df = df.drop('county', axis=1)\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    merged_matrix = df.merge(df_order, left_on='emm', right_on='emm_intersect', how='left')\n",
    "    sorted_matrix = merged_matrix.sort_values(by='no')\n",
    "    sorted_matrix = sorted_matrix.drop(sorted_matrix.columns[-2:], axis=1)\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "\n",
    "    return(sorted_matrix)\n",
    "    \n",
    "def eu_rows(df, category, columns_dict, threshold=1):\n",
    "    # threshold means, minimum 1 col in the dict is non-zero\n",
    "    columns = columns_dict.get(category, [])\n",
    "    mask = (df[columns] != 0).sum(axis=1) >= threshold\n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df\n",
    "\n",
    "def eu_rows_woutthreshold(df, category, columns_dict):\n",
    "    columns = columns_dict.get(category, [])\n",
    "    mask = (df[columns] != 0).all(axis=1)\n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df\n",
    "    \n",
    "def convert_matrix_stock(sector,filedir, filename, weathers, mymap, fueltype):\n",
    "    conditions_dict = mymap[sector][fueltype]\n",
    "        \n",
    "    if sector == \"commercial\":\n",
    "        sec = \"Com\"\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        # area_col = \"weight\"\n",
    "        area_col = \"calc.weighted.sqft\"\n",
    "    else:\n",
    "        sec = \"Res\"\n",
    "        county_col = \"in.county\"\n",
    "        area_col = \"in.units_represented\"\n",
    "        # area_col = \"weight\"\n",
    "    \n",
    "    for weath in weathers:    \n",
    "        alldf = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        alldf.rename(columns={county_col: \"county\"}, inplace=True)\n",
    "        alldf.rename(columns={\"in.state\": \"state\"}, inplace=True)\n",
    "        alldf.rename(columns={area_col: \"warea\"}, inplace=True)\n",
    "        \n",
    "        mykeys = list(mymap[sector][fueltype])\n",
    "        \n",
    "        norm_pd = pd.DataFrame()\n",
    "        convert_pd = pd.DataFrame()\n",
    "        \n",
    "        for eu in mykeys:\n",
    "            df = eu_rows(alldf, eu, conditions_dict)\n",
    "    \n",
    "            df = apply_geographies(df, scoutgeo_df, geos)\n",
    "            df = df[[\"warea\",\"emm\",\"cdiv\"]] #\"state\",\"weight\",\"in.sqft\"]]\n",
    "            \n",
    "            conversion_matrix = df.pivot_table(index='emm', columns='cdiv', values=\"warea\", aggfunc='sum')\n",
    "            convert_matrix = output(conversion_matrix.reset_index())\n",
    "            convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "            normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "            normalized_matrix = output(normalized_matrix)\n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "            normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "            normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "            normalized_matrix = normalized_matrix.iloc[1:]\n",
    "            normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "            normalized_matrix.insert(0, 'End use', eu)\n",
    "            normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "            norm_pd = normalized_matrix if norm_pd.empty else pd.concat([norm_pd, normalized_matrix], ignore_index=False)\n",
    "        if sec == \"Res\": norm_pd['AK_HI'] = 0     \n",
    "        norm_pd.to_csv(f\"./{outdir}/{sec}_Cdiv_EMM_{weath}_{remove_space(fueltype)}_Stock.csv\", index=False)\n",
    "################################################################################\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_end_use'\n",
    "building_types = ['commercial','residential']\n",
    "geos = ['emm', 'cdiv']\n",
    "fuel_com = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "fuel_res = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "\n",
    "print(\"COMMERCIAL\")\n",
    "for fl in fuel_com:\n",
    "    convert_matrix_stock(\n",
    "        sector = \"commercial\",\n",
    "        filedir = f\"./{fdir}/2024_comstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype =fl\n",
    "    )\n",
    "\n",
    "print(\"RESIDENTIAL\")\n",
    "for fl in fuel_res:\n",
    "    convert_matrix_stock(\n",
    "        sector = \"residential\",\n",
    "        filedir = f\"./{fdir}/2024_resstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype = fl\n",
    "    )\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb387ce9-908f-4465-aff9-dc5648a6db14",
   "metadata": {},
   "source": [
    "### CDIV/STATE - ENERGY (END USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf9038-a2d2-4b09-b2f9-48792187df6b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Energy ###\n",
    "### ResStock 2022 ComStock 2023\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    # df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    # df.loc[df['state'] == 'HI', 'county'] = 'G1'\n",
    "    for geo in geos:\n",
    "        geocol = 'cdiv' if geo == 'cdiv' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)          \n",
    "    df = df.drop('county', axis=1)\n",
    "    # print((df[df['state'].isnull()])['state'])\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    # merged_matrix = df.merge(df_order, left_on='cdiv', right_on='cdiv_intersect', how='left')\n",
    "    # sorted_matrix = merged_matrix.sort_values(by='no')\n",
    "    # sorted_matrix = sorted_matrix.drop(sorted_matrix.columns[-2:], axis=1)\n",
    "    sorted_matrix = df\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "    return(sorted_matrix)\n",
    "\n",
    "\n",
    "def convert_matrix(sector,filedir, filename, weathers, mymap, fueltype):\n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        sec = \"Res\"\n",
    "    \n",
    "    mykeys = list(mymap[sector][fueltype])\n",
    "    for weath in weathers:\n",
    "        df = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "\n",
    "        # list_ak_counties = (df[df['in.state'] == 'AK']['in.county']).to_list()\n",
    "        # list_hi_counties = (df[df['in.state'] == 'hi']['in.county']).to_list()\n",
    "        # filtered_values = df[df['in.county'].isin(list_hi_counties)]['in.county']\n",
    "        # for value in filtered_values:\n",
    "        #     print(value)\n",
    "        \n",
    "        df.rename(columns={county_col: 'county'}, inplace=True)\n",
    "        df.rename(columns={'in.state': 'state'}, inplace=True)\n",
    "        for eu in mykeys:\n",
    "            df[eu] = df[mymap[sector][fueltype][eu]].sum(axis=1)\n",
    "        df.reset_index(inplace=True)\n",
    "        df = apply_geographies(df, scoutgeo_df, geos)\n",
    "        df = df.dropna(subset=geos)\n",
    "        df = df[geos+mykeys]\n",
    "        df = df.groupby(['cdiv', 'state']).sum().reset_index()\n",
    "        norm_pd = pd.DataFrame()\n",
    "        convert_pd = pd.DataFrame()\n",
    "        for eu in mykeys:\n",
    "            conversion_matrix = df.pivot(index='state', columns='cdiv', values=eu)\n",
    "            convert_matrix = output(conversion_matrix.reset_index())\n",
    "            convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "            normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "            normalized_matrix = output(normalized_matrix)\n",
    "            \n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "            normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "            normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "            normalized_matrix = normalized_matrix.iloc[1:]\n",
    "            normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "            normalized_matrix.insert(0, 'End use', eu)\n",
    "            normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "            norm_pd = normalized_matrix if norm_pd.empty else pd.concat([norm_pd, normalized_matrix], ignore_index=False)\n",
    "        if sec == \"Res\":\n",
    "            norm_pd['AK'] = 0\n",
    "            norm_pd['HI'] = 0\n",
    "        norm_pd.to_csv(f\"./{outdir}/{sec}_Cdiv_State_{weath}_{remove_space(fueltype)}.csv\", index=False)\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_end_use'\n",
    "building_types = ['commercial','residential']\n",
    "lst_ak_counties = []\n",
    "lst_hi_counties = []\n",
    "\n",
    "geos = ['cdiv', 'state']\n",
    "fuel_com = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "fuel_res = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "################################################################################\n",
    "print(\"COMMERCIAL\")\n",
    "for fl in fuel_com:\n",
    "    convert_matrix(\n",
    "        sector = \"commercial\",\n",
    "        filedir = f\"./{fdir}/2024_comstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype = fl\n",
    "    )\n",
    "print(\"RESIDENTIAL\")\n",
    "for fl in fuel_res:\n",
    "    convert_matrix(\n",
    "        sector = \"residential\",\n",
    "        filedir = f\"./{fdir}/2024_resstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype = fl\n",
    "    )\n",
    "################################################################################\n",
    "print (\"COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1801df-7f79-4d2a-8182-bed4f78bafdf",
   "metadata": {},
   "source": [
    "### CDIV/STATE - STOCK (END USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818dfa0-2709-4085-ad6e-ef6342d8cf62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    # df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    # df.loc[df['state'] == 'HI', 'county'] = 'G1'\n",
    "    for geo in geos:\n",
    "        geocol = 'cdiv' if geo == 'cdiv' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)          \n",
    "    df = df.drop('county', axis=1)\n",
    "    # print((df[df['state'].isnull()])['state'])\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    # merged_matrix = df.merge(df_order, left_on='cdiv', right_on='cdiv_intersect', how='left')\n",
    "    # sorted_matrix = merged_matrix.sort_values(by='no')\n",
    "    # sorted_matrix = sorted_matrix.drop(sorted_matrix.columns[-2:], axis=1)\n",
    "    sorted_matrix = df\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)  ### to transpose CDIV on the row and EMM on the columns\n",
    "    return(sorted_matrix)\n",
    "\n",
    "\n",
    "def eu_rows(df, category, columns_dict, threshold=1):\n",
    "    # threshold means, minimum 1 col in the dict is non-zero\n",
    "    columns = columns_dict.get(category, [])\n",
    "    mask = (df[columns] != 0).sum(axis=1) >= threshold\n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df\n",
    "\n",
    "def eu_rows_woutthreshold(df, category, columns_dict):\n",
    "    columns = columns_dict.get(category, [])\n",
    "    mask = (df[columns] != 0).all(axis=1)\n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df\n",
    "    \n",
    "def convert_matrix_stock(sector,filedir, filename, weathers, mymap, fueltype):\n",
    "    conditions_dict = mymap[sector][fueltype]\n",
    "    if sector == \"commercial\":\n",
    "        sec = \"Com\"\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        # area_col = \"weight\"\n",
    "        area_col = \"calc.weighted.sqft\"\n",
    "    else:\n",
    "        sec = \"Res\"\n",
    "        county_col = \"in.county\"\n",
    "        area_col = \"in.units_represented\"\n",
    "        # area_col = \"weight\"\n",
    "        \n",
    "    for weath in weathers:    \n",
    "        alldf = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        alldf.rename(columns={county_col: \"county\"}, inplace=True)\n",
    "        alldf.rename(columns={\"in.state\": \"state\"}, inplace=True)\n",
    "        alldf.rename(columns={area_col: \"warea\"}, inplace=True)\n",
    "        \n",
    "        mykeys = list(mymap[sector][fueltype])\n",
    "        \n",
    "        norm_pd = pd.DataFrame()\n",
    "        convert_pd = pd.DataFrame()\n",
    "        \n",
    "        for eu in mykeys:\n",
    "            df = eu_rows(alldf, eu, conditions_dict)\n",
    "            df = apply_geographies(df, scoutgeo_df, geos)\n",
    "            # df = df.dropna(subset=geos)\n",
    "            df = df[[\"warea\",\"state\",\"cdiv\"]] #\"state\",\"weight\",\"in.sqft\"]]\n",
    "            conversion_matrix = df.pivot_table(index='state', columns='cdiv', values=\"warea\", aggfunc='sum')\n",
    "            convert_matrix = output(conversion_matrix.reset_index())\n",
    "            convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "            normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "            normalized_matrix = output(normalized_matrix)\n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "            normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "            normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "            normalized_matrix = normalized_matrix.iloc[1:]\n",
    "            normalized_matrix.insert(0, 'CDIV', normalized_matrix.index)\n",
    "            normalized_matrix.insert(0, 'End use', eu)\n",
    "            normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "            norm_pd = normalized_matrix if norm_pd.empty else pd.concat([norm_pd, normalized_matrix], ignore_index=False)\n",
    "        if sec == \"Res\": \n",
    "            norm_pd['AK'] = 0\n",
    "            norm_pd['HI'] = 0    \n",
    "        norm_pd.to_csv(f\"./{outdir}/{sec}_Cdiv_State_{weath}_{remove_space(fueltype)}_Stock.csv\", index=False)\n",
    "################################################################################\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_end_use'\n",
    "building_types = ['commercial','residential']\n",
    "lst_ak_counties = []\n",
    "lst_hi_counties = []\n",
    "\n",
    "geos = ['cdiv', 'state']\n",
    "fuel_com = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "fuel_res = ['electricity', 'natural gas', 'distillate', 'other fuel']\n",
    "################################################################################'\n",
    "building_types = ['commercial','residential']\n",
    "lst_ak_counties = []\n",
    "lst_hi_counties = []\n",
    "\n",
    "geos = ['cdiv', 'state']\n",
    "\n",
    "print(\"COMMERCIAL\")\n",
    "for fl in fuel_com:\n",
    "    convert_matrix_stock(\n",
    "        sector = \"commercial\",\n",
    "        filedir = f\"./{fdir}/2024_comstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype = fl\n",
    "    )\n",
    "print(\"RESIDENTIAL\")\n",
    "for fl in fuel_res:\n",
    "    convert_matrix_stock(\n",
    "        sector = \"residential\",\n",
    "        filedir = f\"./{fdir}/2024_resstock/\",\n",
    "        filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "        weathers = ['amy2018'],\n",
    "        mymap = enduse_map,\n",
    "        fueltype = fl\n",
    "    )\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2d6fd-9b2c-44bb-8b3d-170308f22810",
   "metadata": {},
   "source": [
    "### STATE/EMM - ENERGY (END USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbec6f0-5a58-4b8c-884d-6949557c0735",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ResStock 2024 ComStock 2024\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def apply_geographies(df, dfdict, geos):\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    df.loc[df['state'] == 'AK', 'county'] = 'G0'\n",
    "    df.loc[df['state'] == 'HI', 'county'] = 'G1'    \n",
    "    for geo in geos:\n",
    "        geocol = 'emm2020_county' if geo == 'emm' else geo\n",
    "        d = dfdict.set_index('gisjoin').T.to_dict('index')[geocol]\n",
    "        df[geo] = df['county'].map(d)\n",
    "    df = df.drop('county', axis=1)\n",
    "    return df\n",
    "\n",
    "def output(df):\n",
    "    merged_matrix = df.merge(df_order, left_on='emm', right_on='emm_intersect', how='left')\n",
    "    sorted_matrix = merged_matrix.sort_values(by='no')\n",
    "    sorted_matrix = sorted_matrix.drop(sorted_matrix.columns[-2:], axis=1)\n",
    "    sorted_matrix.loc['total'] = sorted_matrix.sum()\n",
    "    sorted_matrix = transpose(sorted_matrix)\n",
    "    return(sorted_matrix)\n",
    "\n",
    "\n",
    "def convert_matrix(sector,filedir, filename, weathers, mymap):\n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        sec = \"Res\"\n",
    "    \n",
    "    mykeys = list(mymap[sector])\n",
    "    for weath in weathers:\n",
    "        df = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "\n",
    "        # list_ak_counties = (df[df['in.state'] == 'AK']['in.nhgis_county_gisjoin']).to_list()\n",
    "        # list_hi_counties = (df[df['in.state'] == 'hi']['in.nhgis_county_gisjoin']).to_list()\n",
    "        # filtered_values = df[df['in.county'].isin(list_hi_counties)]['in.county']\n",
    "        # for value in filtered_values:\n",
    "        #     print(value)\n",
    "        \n",
    "        df.rename(columns={county_col: 'county'}, inplace=True)\n",
    "        df.rename(columns={'in.state': 'state'}, inplace=True)\n",
    "        for eu in mykeys:\n",
    "            df[eu] = df[mymap[sector][eu]].sum(axis=1)\n",
    "        df.reset_index(inplace=True)\n",
    "        df = apply_geographies(df, scoutgeo_df, geos)\n",
    "        df = df.dropna(subset=geos)\n",
    "        df = df[geos+mykeys]\n",
    "        df = df.groupby(['emm', 'state']).sum().reset_index()\n",
    "        norm_pd = pd.DataFrame()\n",
    "        convert_pd = pd.DataFrame()\n",
    "        for eu in mykeys:\n",
    "            # sdf = df[['emm','cdiv','total_elec']]\n",
    "            conversion_matrix = df.pivot(index='emm', columns='state', values=eu)\n",
    "            convert_matrix = output(conversion_matrix.reset_index())\n",
    "            convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "            normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "            normalized_matrix = output(normalized_matrix)\n",
    "\n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "            normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "            normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "            normalized_matrix = normalized_matrix.iloc[1:]\n",
    "            normalized_matrix.insert(0, 'State', normalized_matrix.index)\n",
    "            normalized_matrix.insert(0, 'End use', eu)\n",
    "            normalized_matrix.drop(columns=['Total'], inplace=True)\n",
    "            norm_pd = normalized_matrix if norm_pd.empty else pd.concat([norm_pd, normalized_matrix], ignore_index=False)\n",
    "        norm_pd.to_csv(f\"./{outdir}/{sec}_State_EMM_{weath}.csv\", index=False)\n",
    "\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_end_use'\n",
    "building_types = ['commercial','residential']\n",
    "\n",
    "\n",
    "geos = ['emm', 'state']\n",
    "################################################################################\n",
    "\n",
    "print(\"COMMERCIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"commercial\",\n",
    "    filedir = f\"./{fdir}/2024_comstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = enduse_map)\n",
    "print(\"RESIDENTIAL\")\n",
    "convert_matrix(\n",
    "    sector = \"residential\",\n",
    "    filedir = f\"./{fdir}/2024_resstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['tmy3','amy2018'],\n",
    "    mymap = enduse_map)\n",
    "################################################################################\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb2353-f4d6-4fd8-92fe-b940c148d9f4",
   "metadata": {},
   "source": [
    "### STATE/EMM - STOCK (END USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206b1a4-f3d0-42f0-87c7-eb2cb7c9fdc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def eu_rows(df, category, columns_dict, threshold=1):\n",
    "    # threshold means, minimum 1 col in the dict is non-zero\n",
    "    columns = columns_dict.get(category, [])\n",
    "    mask = (df[columns] != 0).sum(axis=1) >= threshold\n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df\n",
    "\n",
    "def eu_rows_woutthreshold(df, category, columns_dict):\n",
    "    columns = columns_dict.get(category, [])\n",
    "    mask = (df[columns] != 0).all(axis=1)\n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df\n",
    "    \n",
    "def convert_matrix_stock(sector,filedir, filename, weathers, mymap):\n",
    "    conditions_dict = mymap[sector]\n",
    "    if sector == \"commercial\":\n",
    "        county_col = \"in.nhgis_county_gisjoin\"\n",
    "        area_col = \"calc.weighted.sqft\"\n",
    "        sec = \"Com\"\n",
    "    else:\n",
    "        county_col = \"in.county\"\n",
    "        area_col = \"weight\"\n",
    "        sec = \"Res\"\n",
    "        \n",
    "    for weath in weathers:    \n",
    "        alldf = pd.read_parquet(f\"{filedir}{weath}/{filename}\", engine='pyarrow')\n",
    "        alldf.rename(columns={county_col: \"county\"}, inplace=True)\n",
    "        alldf.rename(columns={\"in.state\": \"state\"}, inplace=True)\n",
    "        alldf.rename(columns={area_col: \"warea\"}, inplace=True)\n",
    "        \n",
    "        mykeys = list(mymap[sector])\n",
    "        \n",
    "        norm_pd = pd.DataFrame()\n",
    "        convert_pd = pd.DataFrame()\n",
    "        \n",
    "        for eu in mykeys:\n",
    "            df = eu_rows(alldf, eu, conditions_dict)\n",
    "            df = apply_geographies(df, scoutgeo_df, geos)\n",
    "            # df = df.dropna(subset=geos)\n",
    "            df = df[[\"warea\",\"state\",\"emm\"]] #\"state\",\"weight\",\"in.sqft\"]]\n",
    "            \n",
    "            conversion_matrix = df.pivot_table(index='emm', columns='state', values=\"warea\", aggfunc='sum')\n",
    "            convert_matrix = output(conversion_matrix.reset_index())\n",
    "            convert_pd = convert_matrix if convert_pd.empty else pd.concat([convert_pd, convert_matrix], ignore_index=False)\n",
    "            normalized_matrix = conversion_matrix.div(conversion_matrix.sum(axis=0), axis=1).reset_index()\n",
    "            normalized_matrix = output(normalized_matrix)\n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "            normalized_matrix.columns = normalized_matrix.iloc[0]\n",
    "            normalized_matrix.rename(columns={normalized_matrix.columns[-1]: 'Total'}, inplace=True)\n",
    "            normalized_matrix = normalized_matrix.iloc[1:]\n",
    "            normalized_matrix.insert(0, 'emm', normalized_matrix.index)\n",
    "            normalized_matrix.insert(0, 'End use', eu)\n",
    "            norm_pd = normalized_matrix if norm_pd.empty else pd.concat([norm_pd, normalized_matrix], ignore_index=False)\n",
    "            \n",
    "        norm_pd.to_csv(f\"./{outdir}/{sec}_State_EMM_{weath}_Stock.csv\", index=False)\n",
    "################################################################################\n",
    "scoutgeo_df = get_scout_geo()\n",
    "\n",
    "fdir = 'input'\n",
    "outdir = 'output/2024_end_use'\n",
    "building_types = ['commercial','residential']\n",
    "\n",
    "\n",
    "geos = ['emm', 'state']\n",
    "print(\"COMMERCIAL\")\n",
    "convert_matrix_stock(\n",
    "    sector = \"commercial\",\n",
    "    filedir = f\"./{fdir}/2024_comstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['amy2018'],\n",
    "    mymap = enduse_map)\n",
    "print(\"RESIDENTIAL\")\n",
    "convert_matrix_stock(\n",
    "    sector = \"residential\",\n",
    "    filedir = f\"./{fdir}/2024_resstock/\",\n",
    "    filename = \"baseline_metadata_and_annual_results.parquet\",\n",
    "    weathers = ['tmy3','amy2018'],\n",
    "    mymap = enduse_map)\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
