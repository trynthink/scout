{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759bd7ec-312a-43e0-b56a-810a7a565ca0",
   "metadata": {},
   "source": [
    "## Prepare Scout Data for both RECS and SEDS analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f0b4d-3e6f-4e84-a68d-2b8a3e13778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data preparation for Scout output using Stock data (non-electricity)\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Load the JSON files\n",
    "\n",
    "file_dir = \"test_compare_base_disagg\"\n",
    "recs_or_seds = \"seds\"\n",
    "# recs_or_seds = \"recs\"\n",
    "\n",
    "eussversion = \"2024\"\n",
    "# eussversion = \"2023\"\n",
    "\n",
    "if recs_or_seds == \"recs\":\n",
    "    energy_or_stock = \"stock\"\n",
    "    fueltype = \"electricity\"\n",
    "    if eussversion == \"2024\":\n",
    "        file_paths = [f\"./{file_dir}/jaredstest/mseg_res_com_state_2024_tech_factors.json\", f\"./{file_dir}/2023_work/mseg_res_com_state_2023.json\"]\n",
    "    elif eussversion == \"2023\":\n",
    "        file_paths = [f\"./{file_dir}/2023_work/mseg_res_com_state_2023.json\", f\"./{file_dir}/2023_work/mseg_res_com_state_2023.json\"]\n",
    "elif recs_or_seds == \"seds\":\n",
    "    # projectionyear = \"2023\"\n",
    "    projectionyear = \"2016\"\n",
    "    \n",
    "    fueltype = \"electricity\"\n",
    "    # fueltype = 'natural gas'\n",
    "    \n",
    "    energy_or_stock = \"energy\"\n",
    "\n",
    "    if eussversion == \"2024\":\n",
    "        if fueltype == \"electricity\":\n",
    "            file_paths = [f\"./{file_dir}/jaredstest/mseg_res_com_state_2024_tech_factors.json\", f\"./{file_dir}/2023_work/mseg_res_com_state_2023.json\"]\n",
    "        elif fueltype == \"natural gas\":\n",
    "            file_paths = [f\"./{file_dir}/jaredstest/mseg_res_com_state_2024_eu_factors.json\", f\"./{file_dir}/2023_work/mseg_res_com_state_2023.json\"]\n",
    "    elif eussversion == \"2023\":\n",
    "        file_paths = [f\"./{file_dir}/2023_work/mseg_res_com_state_2023.json\", f\"./{file_dir}/2023_work/mseg_res_com_state_2023.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0446b6-514a-4d7f-8bb0-ba3f0d470c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for path in file_paths:\n",
    "    with open(path, \"r\") as file:\n",
    "        datasets.append(json.load(file))\n",
    "\n",
    "states = set(datasets[0].keys()).intersection(set(datasets[1].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94375f83-7b18-42f8-9e86-0c1413ec8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_overall_data(fueltype, energy_or_stock, rettype):\n",
    "\n",
    "    end_uses_all = set()\n",
    "    for state in states:\n",
    "        for building_type in datasets[0][state]:\n",
    "            for energy_source in datasets[0][state][building_type]: \n",
    "                if energy_source == fueltype:\n",
    "                    end_uses_all.update(datasets[0][state][building_type][energy_source].keys())\n",
    "    \n",
    "    res_bldgs = ['single family home', 'multi family home', 'mobile home']\n",
    "    end_uses_all = list(end_uses_all) \n",
    "    end_uses_wsupply = [\"heating\", \"cooling\", \"secondary heating\"]\n",
    "    years = [str(year) for year in range(2015, 2051)]\n",
    "    \n",
    "    allbldgs_data = [{state: {end_use: {year: 0 for year in years} for end_use in end_uses_all} for state in states} for _ in range(2)]\n",
    "    resbldgs_data = [{state: {end_use: {year: 0 for year in years} for end_use in end_uses_all} for state in states} for _ in range(2)]\n",
    "    combldgs_data = [{state: {end_use: {year: 0 for year in years} for end_use in end_uses_all} for state in states} for _ in range(2)]\n",
    "    \n",
    "    def is_valid_stock(stock):\n",
    "        # If stock is a string and equals \"NA\", it's not valid.\n",
    "        if isinstance(stock, str):\n",
    "            if stock == \"NA\":\n",
    "                return False\n",
    "            # Otherwise, if it's a non-\"NA\" string, you could choose to accept or reject it.\n",
    "            return True\n",
    "    \n",
    "        # If stock is a dictionary, check its year values.\n",
    "        elif isinstance(stock, dict):\n",
    "            # If the dictionary is empty, it isn't valid.\n",
    "            if not stock:\n",
    "                return False\n",
    "            # If all values in the dictionary are 0.0, then it's not valid.\n",
    "            if all(float(value) == 0.0 for value in stock.values()):\n",
    "                return False\n",
    "            # Otherwise, it has at least one non-zero value.\n",
    "            return True\n",
    "    \n",
    "        # Any other type is considered invalid.\n",
    "        return False\n",
    "    \n",
    "    for dataset_index, dataset in enumerate(datasets):\n",
    "        for state in states:\n",
    "            for building_type in dataset [state]:\n",
    "                for energy_source in dataset [state][building_type]:\n",
    "                    if energy_source == fueltype:\n",
    "                        for end_use in dataset [state][building_type][energy_source]:\n",
    "                            if end_use in end_uses_wsupply:\n",
    "                                for subcategory in dataset [state][building_type][energy_source][end_use]['supply']:\n",
    "                                    if is_valid_stock(dataset [state][building_type][energy_source][end_use]['supply'][subcategory][energy_or_stock]):\n",
    "                                        for year, value in dataset [state][building_type][energy_source][end_use]['supply'][subcategory][energy_or_stock].items():\n",
    "                                            if year in allbldgs_data[dataset_index][state][end_use]:\n",
    "                                                allbldgs_data[dataset_index][state][end_use][year] += value\n",
    "                                            if building_type in res_bldgs:\n",
    "                                                if year in resbldgs_data[dataset_index][state][end_use]:\n",
    "                                                    resbldgs_data[dataset_index][state][end_use][year] += value\n",
    "                                            if building_type not in res_bldgs:\n",
    "                                                if year in combldgs_data[dataset_index][state][end_use]:\n",
    "                                                    combldgs_data[dataset_index][state][end_use][year] += value\n",
    "                            if end_use not in end_uses_wsupply:\n",
    "                                for subcategory in dataset [state][building_type][energy_source][end_use]:\n",
    "                                    if subcategory != 'energy' and subcategory != 'stock':\n",
    "                                        if is_valid_stock(dataset [state][building_type][energy_source][end_use][subcategory][energy_or_stock]):\n",
    "                                            for year, value in dataset [state][building_type][energy_source][end_use][subcategory][energy_or_stock].items():\n",
    "                                                if year in allbldgs_data[dataset_index][state][end_use]:  # Ensure year is valid\n",
    "                                                    allbldgs_data[dataset_index][state][end_use][year] += value\n",
    "                                                if building_type in res_bldgs:\n",
    "                                                    if year in resbldgs_data[dataset_index][state][end_use]:\n",
    "                                                        resbldgs_data[dataset_index][state][end_use][year] += value\n",
    "                                                if building_type not in res_bldgs:\n",
    "                                                    if year in combldgs_data[dataset_index][state][end_use]:\n",
    "                                                        combldgs_data[dataset_index][state][end_use][year] += value\n",
    "                                    else:\n",
    "                                        if is_valid_stock(dataset [state][building_type][energy_source][end_use][energy_or_stock]):\n",
    "                                            for year, value in dataset [state][building_type][energy_source][end_use][energy_or_stock].items():\n",
    "                                                if year in allbldgs_data[dataset_index][state][end_use]:  # Ensure year is valid\n",
    "                                                    allbldgs_data[dataset_index][state][end_use][year] += value\n",
    "                                                if building_type in res_bldgs:\n",
    "                                                    if year in resbldgs_data[dataset_index][state][end_use]:\n",
    "                                                        resbldgs_data[dataset_index][state][end_use][year] += value\n",
    "                                                if building_type not in res_bldgs:\n",
    "                                                    if year in combldgs_data[dataset_index][state][end_use]:\n",
    "                                                        combldgs_data[dataset_index][state][end_use][year] += value\n",
    "    print(f\"{fueltype}: COMBINE ALL SECTORS\")\n",
    "    allbldgs_dfs = [\n",
    "        {state: pd.DataFrame.from_dict(allbldgs_data[dataset_index][state], orient=\"index\", columns=years).T for state in states}\n",
    "        for dataset_index in range(2)\n",
    "    ]\n",
    "    \n",
    "    print(f\"{fueltype}: RESIDENTIAL SECTOR\")\n",
    "    resbldgs_dfs = [\n",
    "        {state: pd.DataFrame.from_dict(resbldgs_data[dataset_index][state], orient=\"index\", columns=years).T for state in states}\n",
    "        for dataset_index in range(2)\n",
    "    ]\n",
    "    print(f\"{fueltype}: COMMERCIAL SECTOR\")\n",
    "    combldgs_dfs = [\n",
    "        {state: pd.DataFrame.from_dict(combldgs_data[dataset_index][state], orient=\"index\", columns=years).T for state in states}\n",
    "        for dataset_index in range(2)\n",
    "    ]\n",
    "    if rettype:\n",
    "        return resbldgs_data, combldgs_data\n",
    "    else:\n",
    "        return resbldgs_dfs, combldgs_dfs\n",
    "\n",
    "scout_res_elec_eu, scout_com_elec_eu = get_overall_data(\"electricity\", \"energy\", True)\n",
    "scout_res_ng_eu, scout_com_ng_eu = get_overall_data(\"natural gas\", \"energy\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fffc48-095f-42c9-a0b4-c83d26fbc5b9",
   "metadata": {},
   "source": [
    "## Validate with SEDS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0e993-6b68-44e8-9f07-a4c4486f1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Scout results\n",
    "def convert_to_df_for_seds(data, yr, title):\n",
    "    # Initialize lists to store the data\n",
    "    rows = []\n",
    "    \n",
    "    # Process the nested dictionary\n",
    "    for state, end_uses in data.items():  # Directly iterate over the dictionary\n",
    "        for end_use, years in end_uses.items():\n",
    "            for year, value in years.items():\n",
    "                row = {\n",
    "                    'state': state,\n",
    "                    'year': year,\n",
    "                    'end_use': end_use,\n",
    "                    'value': value\n",
    "                }\n",
    "                rows.append(row)\n",
    "    \n",
    "    # Create DataFrame in long format\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df[df['year'] == yr]\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated(subset=['state', 'year', 'end_use'], keep=False)\n",
    "    if duplicates.any():\n",
    "    \n",
    "        # Add a count column to handle duplicates\n",
    "        df['count'] = df.groupby(['state', 'year', 'end_use']).cumcount()\n",
    "        # Create unique end_use names by adding count suffix for duplicates\n",
    "        df['end_use_unique'] = df.apply(lambda x: f\"{x['end_use']}_{x['count']}\" if x['count'] > 0 else x['end_use'], axis=1)\n",
    "        \n",
    "        # Pivot to wide format using the unique end_use names\n",
    "        df_pivot = df.pivot(index=['state', 'year'], \n",
    "                           columns='end_use_unique', \n",
    "                           values='value').reset_index()\n",
    "    else:\n",
    "        # print(\"No duplicates found, converting to wide format directly\")\n",
    "        # If no duplicates, use regular pivot\n",
    "        df_pivot = df.pivot(index=['state', 'year'], \n",
    "                           columns='end_use', \n",
    "                           values='value').reset_index()\n",
    "    \n",
    "    numeric_columns = [col for col in df_pivot.columns if col not in ['state', 'year']]\n",
    "    df_pivot[title] = df_pivot[numeric_columns].sum(axis=1)\n",
    "    df_pivot = df_pivot[['state', title]]\n",
    "    # print(df_pivot.to_string(index=False))\n",
    "    return df_pivot\n",
    "\n",
    "\n",
    "scout_res_elec = convert_to_df_for_seds(scout_res_elec_eu[0],projectionyear, 'scout_res_elec')\n",
    "scout_com_elec = convert_to_df_for_seds(scout_com_elec_eu[0], projectionyear, 'scout_com_elec')\n",
    "scout_res_ng = convert_to_df_for_seds(scout_res_ng_eu[0],projectionyear, 'scout_res_ng')\n",
    "scout_com_ng = convert_to_df_for_seds(scout_com_ng_eu[0], projectionyear, 'scout_com_ng')\n",
    "\n",
    "scout_dat = pd.merge(scout_res_elec, scout_com_elec, on='state', how='inner')\n",
    "scout_dat = pd.merge(scout_dat, scout_res_ng, on='state', how='inner')\n",
    "scout_dat = pd.merge(scout_dat, scout_com_ng, on='state', how='inner')\n",
    "# print(scout_dat.to_string(index=False))\n",
    "\n",
    "elec_factor = 0.29307107\n",
    "ng_factor = 1e6 # 1,000,000\n",
    "\n",
    "# Apply multiplications to the respective columns\n",
    "scout_dat['scout_res_elec_mwh'] = scout_dat['scout_res_elec'] * elec_factor\n",
    "scout_dat['scout_com_elec_mwh'] = scout_dat['scout_com_elec'] * elec_factor\n",
    "scout_dat['scout_res_ng_tbtu'] = scout_dat['scout_res_ng'] / ng_factor\n",
    "scout_dat['scout_com_ng_tbtu'] = scout_dat['scout_com_ng'] / ng_factor\n",
    "scout_dat.to_csv(f\"./{file_dir}/scout_dat_euss{eussversion}_proj{projectionyear}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515b22c-45d9-4132-afd6-497915bd7078",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# https://www.eia.gov/state/seds/data.cfm?incfile=/state/seds/sep_fuel/html/fuel_use_ng.html&sid=US&sid=CA\n",
    "# https://www.eia.gov/electricity/data/state/xls/861/HS861%202010-.xlsx\n",
    "\n",
    "seds_dir = \"seds\"\n",
    "if projectionyear == \"2016\":\n",
    "    seds_file = \"seds2016.csv\"\n",
    "elif projectionyear == \"2023\":\n",
    "    seds_file = \"seds2023.csv\"\n",
    "seds_file_path = os.path.join(seds_dir, seds_file)\n",
    "seds_dat = pd.read_csv(seds_file_path)\n",
    "\n",
    "scout_seds_dat = pd.merge(scout_dat, seds_dat, on='state', how='inner')\n",
    "scout_seds_dat = scout_seds_dat[~scout_seds_dat['state'].isin(['AK', 'HI'])]\n",
    "# scout_seds_dat.to_csv(\"scout_seds_dat.csv\", index=False)\n",
    "# print(scout_seds_dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03344d50-e03a-4c55-8aa8-13f888cf0095",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = scout_seds_dat\n",
    "file_dir = \"test_compare_base_disagg\"\n",
    "pairs = [\n",
    "    ('scout_res_elec_mwh', 'seds_res_elec_mwh', 'Residential Electricity'),\n",
    "    ('scout_com_elec_mwh', 'seds_com_elec_mwh', 'Commercial Electricity'),\n",
    "    ('scout_res_ng_tbtu', 'seds_res_ng_tbtu', 'Residential Natural Gas'),\n",
    "    ('scout_com_ng_tbtu', 'seds_com_ng_tbtu', 'Commercial Natural Gas')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.flatten()  # Flatten the 2x2 array for easier iteration\n",
    "\n",
    "# Plot each pair in the grid\n",
    "for idx, (x_col, y_col, title_prefix) in enumerate(pairs):\n",
    "    if \"Electricity\" in title_prefix:\n",
    "        lbl_unit = 'MWh'\n",
    "    else:\n",
    "        lbl_unit = 'TBtu'\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(df[x_col], df[y_col], color='blue', label='States')\n",
    "    \n",
    "    # Add state labels\n",
    "    for i, state in enumerate(df['state']):\n",
    "        ax.text(df[x_col].iloc[i], df[y_col].iloc[i], state, fontsize=8, ha='right')\n",
    "    \n",
    "    # Plot y=x line\n",
    "    max_val = max(df[x_col].max(), df[y_col].max())\n",
    "    min_val = min(df[x_col].min(), df[y_col].min())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(f\"Scout ({lbl_unit})\", fontsize=10)\n",
    "    ax.set_ylabel(f\"SEDS ({lbl_unit})\", fontsize=10)\n",
    "    ax.set_title(f'Scout and SEDS ({title_prefix})\\nEUSS={eussversion},Proj.={projectionyear}', fontsize=12)\n",
    "    \n",
    "    # Set scientific notation for axes\n",
    "    ax.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./{file_dir}/scout_seds_EUSS{eussversion}_{fueltype}{projectionyear}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55452dd-c298-4326-a0f9-002a30eedffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f51ca8a2-ff2f-487c-8f40-c4f00ebab65b",
   "metadata": {},
   "source": [
    "## Validate with RECS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c7643-841a-49cb-8355-9edb43fff4e4",
   "metadata": {},
   "source": [
    "### Prepare Scout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1723b-47f5-48b9-a72f-72fd8a10fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_wscoutgeo_cdiv_calc(df):\n",
    "    scoutgeo = f\"new_scout_geography.csv\"\n",
    "    scoutgeo_df = pd.read_csv(scoutgeo)\n",
    "    new_scoutgeo_df = scoutgeo_df[['state', 'cdiv', 'cdiv_high']]\n",
    "    new_scoutgeo_df = new_scoutgeo_df.drop_duplicates()    \n",
    "\n",
    "    final_df = df[df['Year'] == '2020']\n",
    "    \n",
    "    final_df = final_df.merge(new_scoutgeo_df, left_on=\"State\", right_on=\"state\", how=\"left\")\n",
    "    final_df.drop(columns=[\"State\"], inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "    return final_df\n",
    "    \n",
    "def merge_dfs(dfs):\n",
    "    merged_dfs = []\n",
    "    \n",
    "    for dataset_index, dataset in enumerate(dfs):\n",
    "        if dataset_index == 0:\n",
    "            for state, df in dataset.items():\n",
    "                df = df.copy()\n",
    "                df['State'] = state\n",
    "                # df['Dataset_Index'] = dataset_index  # Track dataset index\n",
    "                merged_dfs.append(df.reset_index().rename(columns={'index': 'Year'}))\n",
    "    \n",
    "    # Concatenating all dataframes into one\n",
    "    final_df = pd.concat(merged_dfs, ignore_index=True)\n",
    "    final_df2 = merge_wscoutgeo_cdiv_calc(final_df)\n",
    "\n",
    "    columns_of_interest = [\"heating\", \"cooking\", \"water heating\"]\n",
    "    df_totals = final_df2.groupby(\"cdiv\")[columns_of_interest].transform(\"sum\")\n",
    "    \n",
    "    for col in columns_of_interest:\n",
    "        final_df2[f\"{col}_ratio\"] = final_df2[col] / df_totals[col]\n",
    "    \n",
    "    final_df2 = final_df2[['state']+[s + \"_ratio\" for s in columns_of_interest]]\n",
    "    \n",
    "    return final_df2\n",
    "\n",
    "dir_out = \"test_compare_base_disagg\"\n",
    "scout_res_elec, scout_com_elec = get_overall_data(\"electricity\", energy_or_stock, False)\n",
    "\n",
    "merge_dfs(scout_res_elec).to_csv(f\"./{dir_out}/{energy_or_stock}_{eussversion}_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51af3db-d1e6-4abd-aa71-c58b461ce6a5",
   "metadata": {},
   "source": [
    "### Prepare RECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006bea40-1f4b-47be-85b9-0a57724f3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare RECS data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def recs_merge_wscoutgeo_cdiv_calc(df):\n",
    "    scoutgeo = f\"new_scout_geography.csv\"\n",
    "    scoutgeo_df = pd.read_csv(scoutgeo)\n",
    "    new_scoutgeo_df = scoutgeo_df[['state', 'cdiv', 'cdiv_high']]\n",
    "    new_scoutgeo_df = new_scoutgeo_df.drop_duplicates()    \n",
    "\n",
    "    final_df = df\n",
    "    \n",
    "    final_df = final_df.merge(new_scoutgeo_df, left_on=\"State\", right_on=\"state\", how=\"left\")\n",
    "    final_df.drop(columns=[\"State\"], inplace=True, errors='ignore')\n",
    "    return final_df\n",
    "\n",
    "def recs_calc_ratio(data, columns_of_interest):\n",
    "    final_df = data.copy()\n",
    "    final_df = recs_merge_wscoutgeo_cdiv_calc(final_df)\n",
    "\n",
    "    # Replace strings with NaN across all columns of interest\n",
    "    final_df[columns_of_interest] = final_df[columns_of_interest].apply(\n",
    "        lambda x: pd.to_numeric(x, errors='coerce')\n",
    "    )\n",
    "    \n",
    "    # Calculate totals per group, skipping NaN values\n",
    "    df_totals = final_df.groupby(\"cdiv\")[columns_of_interest].transform(\n",
    "        lambda x: x.sum(skipna=True)\n",
    "    )\n",
    "\n",
    "    for col in columns_of_interest:\n",
    "        final_df[f\"{col}_ratio\"] = np.where(\n",
    "            final_df[col].notnull() & df_totals[col].notnull(),\n",
    "            final_df[col] / df_totals[col],\n",
    "            'NA'\n",
    "        )\n",
    "    \n",
    "    final_df = final_df[['state']+[s + \"_ratio\" for s in columns_of_interest]]\n",
    "    return final_df\n",
    "\n",
    "dir_name = \"recs_docs\"\n",
    "dir_out = \"test_compare_base_disagg\"\n",
    "\n",
    "data = pd.read_csv(f\"{dir_name}/state_appliances.csv\")\n",
    "appliances_df = recs_calc_ratio(data, [\"Electric cooking appliance (Number)\"])\n",
    "# appliances_df.to_csv(f\"{dir_out}/recs_appliances.csv\",index=False)\n",
    "\n",
    "data = pd.read_csv(f\"{dir_name}/state_space_heating.csv\")\n",
    "heating_df = recs_calc_ratio(data, [\"Central heat pump (Number)\"])\n",
    "# heating_df.to_csv(f\"{dir_out}/recs_heating.csv\",index=False)\n",
    "\n",
    "data = pd.read_csv(f\"{dir_name}/state_water_heating.csv\")\n",
    "water_heating_df = recs_calc_ratio(data, [\"Electricity (Number)\"])\n",
    "# water_heating_df.to_csv(f\"{dir_out}/recs_water_heating.csv\",index=False)\n",
    "\n",
    "water_heating_df = water_heating_df.rename(columns={\"Electricity (Number)_ratio\": \"recs_water_heating_ratio\"})\n",
    "heating_df = heating_df.rename(columns={\"Central heat pump (Number)_ratio\": \"recs_heating_ratio\"})\n",
    "appliances_df = appliances_df.rename(columns={\"Electric cooking appliance (Number)_ratio\": \"recs_cooking_ratio\"})\n",
    "\n",
    "# Merge the DataFrames on 'state' using outer join\n",
    "recs_df = pd.merge(water_heating_df, heating_df, on=\"state\", how=\"outer\")\n",
    "recs_df = pd.merge(recs_df, appliances_df, on=\"state\", how=\"outer\")\n",
    "recs_df.to_csv(f\"{dir_out}/recs_data.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b3d4a-8de9-44e9-8c57-9126a6ed1487",
   "metadata": {},
   "source": [
    "### Analyze with RECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1698f-b42d-4deb-bea0-da6460687dfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ANALYSIS with RECS\n",
    "###########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###########################\n",
    "recs_df = pd.read_csv(f\"{dir_out}/recs_data.csv\")\n",
    "stock_df = pd.read_csv(f\"{dir_out}/{energy_or_stock}_{eussversion}_res.csv\") # Got the data from running 1. Data preparation for Scout output using Stock data\n",
    "stock_recs_df = pd.merge(stock_df, recs_df, on=\"state\", how=\"outer\")\n",
    "stock_recs_df.to_csv(f\"{dir_out}/stock_recs.csv\",index=False)\n",
    "###########################\n",
    "\n",
    "df = stock_recs_df.copy()\n",
    "\n",
    "# Define the pairs of columns to compare\n",
    "comparisons = [\n",
    "    (\"heating_ratio\", \"recs_heating_ratio\", \"Heating (Year 2020)\"),\n",
    "    (\"cooking_ratio\", \"recs_cooking_ratio\", \"Cooking (Year 2020)\"),\n",
    "    (\"water heating_ratio\", \"recs_water_heating_ratio\", \"Water Heating (Year 2020)\")\n",
    "]\n",
    "\n",
    "# Create a 1x3 grid of subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "\n",
    "# Plot each comparison\n",
    "for idx, (x_col, y_col, title) in enumerate(comparisons):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Scatter plot for states (drop rows where either x or y is NaN)\n",
    "    plot_df = df.dropna(subset=[x_col, y_col])\n",
    "    ax.scatter(plot_df[x_col], plot_df[y_col], color='blue', label='States')\n",
    "    \n",
    "    # Add state labels to each point\n",
    "    for i, state in enumerate(plot_df['state']):\n",
    "        ax.annotate(state, (plot_df[x_col].iloc[i], plot_df[y_col].iloc[i]), fontsize=8)\n",
    "    \n",
    "    # Plot y=x line\n",
    "    ax.plot([0, 1], [0, 1], 'r--', label='y = x')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(f\"Using tech factors: {title.split()[0]}\")\n",
    "    ax.set_ylabel(f\"Using RECS: {title.split()[0]}\")\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Set log scale (optional, based on the image; adjust limits as needed)\n",
    "    ax.set_xscale('linear')\n",
    "    ax.set_yscale('linear')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(f\"./{dir_out}/scout_recs_version_{eussversion}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
